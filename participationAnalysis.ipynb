{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60b4db59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import os\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "249136e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def createAnswerKey(fileName):\n",
    "    # open AnswerKey csv file and create a dictionary of all the answers, where the format is (Lecture#, question#): Answer\n",
    "    questionList = []\n",
    "    answers = {}\n",
    "    lectureNum = \"\"\n",
    "    with open(fileName) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        line_count = 0\n",
    "        for row in csv_reader:\n",
    "            if line_count == 0:\n",
    "                questionList = row\n",
    "                line_count+=1\n",
    "            else:\n",
    "                for answerIndex in range(len(row)):\n",
    "                    if answerIndex > 0:\n",
    "                        lectureNum = row[0]\n",
    "                        answer = row[answerIndex]\n",
    "                        answers[(lectureNum,questionList[answerIndex])] = answer\n",
    "\n",
    "                line_count+=1\n",
    "\n",
    "    #print(answers)\n",
    "    return questionList, answers, lectureNum\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dff715ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanAnswer(studAnswer, key):\n",
    "    try:\n",
    "        #fixes bug where TRUE/FALSE answers are output at 1.0 or 0.0\n",
    "        studAnswer = int(float(studAnswer))\n",
    "        if 'False' in key or 'True' in key:\n",
    "            if studAnswer == 0:\n",
    "                return 'False'\n",
    "            else:\n",
    "                return 'True'\n",
    "            \n",
    "        #turns student answers into integers instead of floats\n",
    "        else:\n",
    "            return int(float(studAnswer))\n",
    "    except:\n",
    "        return studAnswer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b85950f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def partAnalysis(fileName, questionList, answers, lectureNum):\n",
    "   #print('reading file', fileName)\n",
    "    response = pd.read_csv(fileName)\n",
    "    analysis = []\n",
    "    allEmails = response['Email Address'].values\n",
    "    answeredQuestions = []\n",
    "    \n",
    "    for question in response:\n",
    "        if question in questionList:\n",
    "            answeredQuestions.append(question)\n",
    "            \n",
    "            countCorrect = 0\n",
    "            countTotal = 0\n",
    "\n",
    "            studentSubmissions = {}\n",
    "            index = 0\n",
    "            \n",
    "            #iterate through all the student responses for the question\n",
    "            for studAnswer in response[question]:  \n",
    "                \n",
    "                #check if valid/non-null submission\n",
    "                if not pd.isnull(studAnswer):\n",
    "                    \n",
    "                    #assign student to their email\n",
    "                    student = allEmails[index]\n",
    "                    \n",
    "                    #check if this is the student's first valid submission \n",
    "                    if student not in studentSubmissions:\n",
    "                        studentSubmissions[student] = studAnswer\n",
    "\n",
    "                     \n",
    "                        studAnswer = cleanAnswer(studAnswer,answers[(lectureNum, question)])\n",
    "                         \n",
    "                        #used 'in' instead of '==' to account for whitespace in answers\n",
    "                        if str(studAnswer) in answers[(lectureNum, question)]:\n",
    "                            \n",
    "            \n",
    "                            countCorrect+=1\n",
    "     \n",
    "            \n",
    "    \n",
    "\n",
    "                        countTotal +=1\n",
    "\n",
    "                index+=1\n",
    "\n",
    "            if countTotal > 0:\n",
    "                #print(countCorrect,\"/\",countTotal)\n",
    "\n",
    "                analysis.append(float(countCorrect/countTotal))\n",
    "                \n",
    "\n",
    "    return analysis, answeredQuestions\n",
    "            \n",
    "        \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "feb2f855",
   "metadata": {},
   "outputs": [],
   "source": [
    "def listToDict(fullLectureAnalysis, qList):\n",
    "    #print(qList)\n",
    "    lectureDict = defaultdict(list)\n",
    "    for i in range(4):\n",
    "        for q in range(len(qList)):\n",
    "            lectureDict[qList[q]].append(fullLectureAnalysis[i][q])\n",
    "            \n",
    "    return lectureDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdaf45fd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "answerList = []\n",
    "\n",
    "for path in pathlib.Path(\"./ANSWERS\").iterdir():\n",
    "    if path.is_file():\n",
    "        answerList.append(str(path))\n",
    "\n",
    "for ans in answerList:\n",
    "    qList, answers, lecNum = createAnswerKey(ans)\n",
    "    #print(f\"------------- Starting {lecNum} -------------\")\n",
    "    lec = lecNum.replace(\" \", \"\").lower()\n",
    "    #print(lec)\n",
    "    for path in pathlib.Path(\"./RESPONSES\").iterdir():\n",
    "        if path.is_dir() and lec in str(path):\n",
    "            \n",
    "            \n",
    "            list_of_files = sorted( filter( lambda x: os.path.isfile(os.path.join(path, x)),\n",
    "                        os.listdir(path) ) )\n",
    "    \n",
    "            fullLectureAnalysis = []\n",
    "            \n",
    "            for file in list_of_files:\n",
    "                analysis, answeredQuestions = partAnalysis(f'{path}/{file}', qList, answers, lecNum)\n",
    "            \n",
    "                fullLectureAnalysis.append(analysis)\n",
    "            \n",
    "                \n",
    "            \n",
    "            lectureDict = listToDict(fullLectureAnalysis, answeredQuestions) \n",
    "\n",
    "            df = pd.DataFrame.from_dict(lectureDict, orient = 'index', columns = ['A00', 'B00', 'C00', 'D00'])\n",
    "            print(df)\n",
    "            #df.to_csv(f'./RESULTS/{lecNum}.csv')\n",
    "            print(f\"------------- OUTPUT {lecNum} TO CSV -------------\")\n",
    "                \n",
    "\n",
    "\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f84106f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'createAnswerKey' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/r8/gfj7vwyj76jg5qqw2n73flkr0000gn/T/ipykernel_26577/1258127696.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#### RANDOM TESTS ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mqList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlecNum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreateAnswerKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./ANSWERS/Lecture Answers - lect3.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-----------------QUESTIONS-----------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'createAnswerKey' is not defined"
     ]
    }
   ],
   "source": [
    "#### RANDOM TESTS ###\n",
    "# qList, answers, lecNum = createAnswerKey('./ANSWERS/Lecture Answers - lect3.csv')\n",
    "# print(answers)\n",
    "\n",
    "# print(\"-----------------QUESTIONS-----------------\")\n",
    "# # for q in qList:\n",
    "# #     print(q)\n",
    "    \n",
    "# #path = \"./TESTING/testDuplicates.csv\"\n",
    "# path = \"./RESPONSES/lecture3/Lecture 3 Participation Form - A00 (Responses).csv\"\n",
    "\n",
    "# analysis, answeredQuestions = partAnalysis(path, qList, answers, lecNum)\n",
    "# print(answeredQuestions)\n",
    "\n",
    "# print(analysis)\n",
    "\n",
    "#print(analysis)\n",
    "#analysis.to_csv(f'./TESTING/TestB00.csv')\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07732a53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
